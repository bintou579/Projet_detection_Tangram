{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Jason_train_files_10082020.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "1z4xy2gTUc4a",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwQtSOz0VrVX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. You will get some practical experience and develop intuition for the following concepts:\n",
        "\n",
        "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
        "* _Overfitting_ —How to identify and prevent it.\n",
        "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmMfiSBcXZST",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1WtoaOHVrVh",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xtzo1yjt6iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Begin by downloading the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bClu_O_Y22wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRucI3QqVrVy",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "PATH = '/content/drive/My Drive/data/final_dataset_balanced/'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "test_dir = os.path.join(PATH, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### Understand the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "Let's look at how many cats and dogs images are in the training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc4u8e9hVrV4",
        "colab": {}
      },
      "source": [
        "num_tr = len(os.listdir(train_dir))\n",
        "num_val = len(os.listdir(test_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGRvlininjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(train_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl8yMKXMihza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "For convenience, set up variables to use while pre-processing the dataset and training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NqNselLVrWA",
        "colab": {}
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Jfk6aSAVrWD"
      },
      "source": [
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "\n",
        "1. Read images from the disk.\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "3. Convert them into floating point tensors.\n",
        "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
        "\n",
        "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBXkzvp5hYOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    validation_split=0.3,\n",
        "                    horizontal_flip=True,\n",
        "                    vertical_flip=True,\n",
        "                    rotation_range=90\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewR8Nw6iJNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = image_gen_train # Generator for our training data\n",
        "validation_image_generator = image_gen_train # Generator for our validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBP7ZNNN-H2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_test = ImageDataGenerator(\n",
        "                    rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh3_bWBxm33t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_image_generator = image_gen_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLciCR_FVrWH"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pw94ajOOVrWI",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size, #directory containing various tangram\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH), # all images will be resized to 150, 150 when it is loaded\n",
        "                                                           class_mode='categorical',\n",
        "                                                           subset='training') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2oUoKUzRVrWM",
        "colab": {}
      },
      "source": [
        "val_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=train_dir,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical',\n",
        "                                                              subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### Visualize training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which are 128 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3f0Z7NZgVrWQ",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "49weMt5YVrWT"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JMt2RES_VrWU",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_VVg_gEVrWW",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SnbEa07X212",
        "colab_type": "text"
      },
      "source": [
        "We are using transfer learning for this application and we chose MobilNetV2 for its light weightness. We will just replace the top layer by a custom layer to match our requirements of 12 different classes to be detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17ER0fGb5Bzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxq2sbg5AJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WuC7Fz75AOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False\n",
        "base_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW5zjCWZ5AE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWWgo4Ce6MCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(12, activation='softmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2A8uVRT6PDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFkHwDn8ouIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 3:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXTyE7l6vbbm",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "We choose the rmsprop optimizer and categorical_crossentropy loss function. To view training and validation accuracy for each training epoch, pass the metrics argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCBIakLZ6Uy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "model.compile(optimizer='Nadam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQpbCx626UnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvRHFhlzpH4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fctcN6ab-reQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uEdyo0N6hQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(val_data_gen, steps = validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-HFAMv3vNip",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5yogePZ6hSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_data_gen,\n",
        "                    epochs=45,\n",
        "                    callbacks=[callback_lr, callback_es],\n",
        "                    validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5syq1JX3-4uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X2EwSTkjyMO",
        "colab_type": "text"
      },
      "source": [
        "### Sauvegarde du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PysqtijFv-HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model.save(\"tangram_jason_mobilenet_final_10082020_2.h5\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "Now visualize the results after training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6oA77ADVrWp",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(12)\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suiTalMJx0ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc[-1], val_acc[-1], loss[-1], val_loss[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5iOvAylw5qx",
        "colab_type": "text"
      },
      "source": [
        "## Definition for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxZv3NipAu9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_osL6Bh7uipt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOEmFAWq9EzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/saved_model/tangram_inceptionV3_full.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R-J74GRnAUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=test_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLJQyqmsnjVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_gen.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyTPiDVynWdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=model.predict_generator(test_data_gen,verbose=1,steps=960/batch_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hZh6NJiwsTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred[1][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-9b3xEQnwMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (train_data_gen.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "result = {}\n",
        "\n",
        "for i in range(len(pred[25])):\n",
        "  result[labels[i]]=pred[25][i]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJnlGmqopakk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0An--dT2oM9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames=test_data_gen.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IKV6VAkp-T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_pred = []\n",
        "\n",
        "for filename in filenames:\n",
        "  real_pred.append(filename.split('/')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJUY29-eyfJ6",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0O4OK4vqhgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(real_pred, predictions, labels=[\"bateau\", \"bol\", \"chat\", \"coeur\", \"cygne\", \"lapin\", \"maison\", \"marteau\", \"montagne\", \"pont\", \"renard\", \"tortue\"])\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXW_Mhro6pS",
        "colab_type": "text"
      },
      "source": [
        "### Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkZzNkfNo9j1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report \n",
        "\n",
        "print(classification_report(real_pred, predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl0zjqt4ycOZ",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laeDajA5s4WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(real_pred, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afxxCL3epd7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R82_t1tdww_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LLLlqM4w_lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ejXAg3zXMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=train_data_gen.class_indices, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dwjnBef_jxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result_image(path):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  ### Preprocessing\n",
        "  start_time_prepro = time.time()\n",
        "  img = cv2.imread(path)\n",
        "  height, width, channels = img.shape\n",
        "  width_cutoff = width // 2\n",
        "  s1 = img[:, :width_cutoff]\n",
        "  s2 = img[:, width_cutoff:]\n",
        "  s1_up = tf.image.resize(s1/255, (224,224), preserve_aspect_ratio=False)\n",
        "  s1_final = tf.expand_dims(s1_up, axis=0)\n",
        "  s2_up = tf.image.resize(s2/255, (224,224), preserve_aspect_ratio=False)\n",
        "  s2_final = tf.expand_dims(s2_up, axis=0)\n",
        "  end_time_prepro = time.time()\n",
        "  print(\"Preprocessing time:\", end_time_prepro - start_time_prepro)\n",
        "\n",
        "  ### Prediction\n",
        "  start_time_pred = time.time()\n",
        "  labels = {0: 'bateau', 1: 'bol', 2: 'chat', 3: 'coeur', 4: 'cygne', 5: 'lapin', 6: 'maison', 7: 'marteau', 8: 'montagne', 9: 'pont', 10: 'renard', 11: 'tortue'}\n",
        "  result_1 = model.predict(s1_final)\n",
        "  result_dict_1 = {}\n",
        "  result_2 = model.predict(s2_final)\n",
        "  result_dict_2 = {}\n",
        "  for i in range(len(result_1[0])):\n",
        "    result_dict_1[labels[i]]=result_1[0][i]\n",
        "    result_dict_2[labels[i]]=result_2[0][i]\n",
        "  end_time_pred = time.time()\n",
        "  print(\"Prediction time:\", end_time_pred - start_time_pred)\n",
        "  \n",
        "  end_time = time.time()\n",
        "  total_fps = 1/(end_time-start_time)\n",
        "  print(\"Total time:\",end_time-start_time)\n",
        "  print(\"FPS:\",total_fps)\n",
        "  return result_dict_1, result_dict_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eV0ECUED00L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_img = \"/content/image1375.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxezUNTeD4Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_image(path_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7TO1GFeD7Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}