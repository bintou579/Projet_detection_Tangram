{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explain how to do the data preparation for the dataset:\n",
    "\n",
    "- To do data augmentation (with bright/blur)\n",
    "- Move each image to each folder of classification\n",
    "- Rename all title of image\n",
    "- Split folder between test/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shutil` module offers a number of high-level operations on files and collections of files. In particular, functions are provided which support file copying and removal. For operations on individual files, see also the `os` module.\n",
    "`OpenCV-Python` is a library of Python bindings designed to solve computer vision problems.\n",
    "And `PIL` is the Python Imaging Library which provides the python interpreter with image editing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/multilabel_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What we have` = The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "|__ <b>multilabel_data</b>\n",
    "    |______ <b>bateau</b>: [bateau.0.jpg, bateau.1.jpg, bateau.2.jpg ....]\n",
    "    |______ <b>bol</b>: [bol.0.jpg, bol.1.jpg, bol.2.jpg ...]\n",
    "    |______ <b>...</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What we want` = The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "<b>dataset</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>bateau</b>: [bateau.0.jpg, bateau.1.jpg, bateau.2.jpg ....]\n",
    "    |______ <b>bol</b>: [bol.0.jpg, bol.1.jpg, bol.2.jpg ...]\n",
    "    |______ <b>...</b>\n",
    "|__ <b>test</b>\n",
    "    |______ <b>bateau</b>: [bateau.2000.jpg, bateau.2001.jpg, bateau.2002.jpg ....]\n",
    "    |______ <b>bol</b>: [bol.2000.jpg, bol.2001.jpg, bol.2002.jpg ...]\n",
    "    |______ <b>...</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (with bright/blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a large dataset is crucial for the performance of the deep learning model. However, we can improve the performance of the model by augmenting the data we already have.\n",
    "- The `ImageEnhance` module contains a number of classes that can be used for image enhancement.\n",
    "- `cv2.blur()` method is used to blur an image using the normalized box filter. The function smooths an image using the kernel which is represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation with bightness\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    new_path = os.path.join(path, directory)\n",
    "    count = 0\n",
    "    for filename in os.listdir(new_path):\n",
    "        if str(filename).startswith(directory):\n",
    "            count = count + 1\n",
    "            img_path = os.path.join(new_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            #image brightness enhancer\n",
    "            enhancer = ImageEnhance.Brightness(img)\n",
    "\n",
    "            factor = 1.5 #brightens the image\n",
    "            im_output = enhancer.enhance(factor)\n",
    "            \n",
    "            #save result image\n",
    "            im_output.save(path+\"/\"+str(directory)+\"/\"+str(directory)+\"_clear_%d.jpg\" % count)\n",
    "        else:\n",
    "              pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation with blur\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    new_path = os.path.join(path, directory)\n",
    "    count = 0\n",
    "    for filename in os.listdir(new_path):\n",
    "        if str(filename).startswith(directory):\n",
    "            count = count + 1\n",
    "            img_path = os.path.join(new_path, filename)\n",
    "            \n",
    "            #read image\n",
    "            src = cv2.imread(img_path)\n",
    "            \n",
    "            # apply guassian blur on src image\n",
    "            rst = cv2.GaussianBlur(src,(3,3),cv2.BORDER_DEFAULT)\n",
    "            \n",
    "            #save result image\n",
    "            cv2.imwrite((path+\"/\"+str(directory)+\"/\"+str(directory)+\"_blur_%d.jpg\" % count),rst)\n",
    "        else:\n",
    "              pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T08:57:55.553460Z",
     "start_time": "2020-08-10T08:57:55.531097Z"
    }
   },
   "source": [
    "## Move image of folder to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name_class = \"tortue\"\n",
    "#path_data = '/multilabel_data/'+name_class\n",
    "#tangram_class = os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with name of all image in folder (of name_class)\n",
    "\n",
    "tangram_class = [(os.listdir(path_data)[i]).lower() for i in range(len(tangram_class))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For select all element \"start with\" to folder tangram_class\n",
    "\n",
    "def list_tangram_class():\n",
    "    list_tangram_class = [tangram_class[elem] for elem in range(len(tangram_class)) if (tangram_class[elem].startswith(\"tortue_blur\") and tangram_class[elem].endswith(\".jpg\"))]\n",
    "    return list_tangram_class\n",
    "\n",
    "files_tangram_class = list_tangram_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For copy file to folder to another folder\n",
    "\n",
    "source=\"/multilabel_data/\"+name_class+\"/\"\n",
    "dest=\"/dataset/train/\"+name_class\n",
    "\n",
    "def copy_file():\n",
    "    for i in range(len(files_tangram_class)):\n",
    "        print(files_tangram_class[i])\n",
    "        # Copy file to another directory\n",
    "        newPath = shutil.copy(source + files_tangram_class[i], dest)\n",
    "        print(\"Path of copied file : \", newPath)   \n",
    "\n",
    "tangram_shape = copy_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rename all element to folder\n",
    "\n",
    "name_class = \"tortue\"\n",
    "source=\"/multilabel_data/\"+name_class                                               \n",
    "dest=\"/dataset/train/\"+name_class\n",
    "\n",
    "def rename_all_img():\n",
    "    count= 0\n",
    "    tangram_class = [(os.listdir(source)[i]).lower() for i in range(len(os.listdir(source)))]\n",
    "    for i in range(len(tangram_class)):\n",
    "        #Copy a file with new name\n",
    "        count = count +1\n",
    "        newPath = shutil.copy(source +\"/\"+ tangram_class[i], dest +\"/\"+ name_class +\".%d.jpg\" % count)\n",
    "        print(\"Path of copied file : \", newPath)\n",
    "        \n",
    "tangram_shape = rename_all_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split folder between train / test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify with the preceding output that we have the same number of images for each category. Letâ€™s now build our smaller dataset, with 20% of train dataset for our test dataset of each categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of img for each categories, and create list of all img for each categories\n",
    "\n",
    "train_dir = \"/dataset/train/\"+name_class\n",
    "string_train = []\n",
    "\n",
    "for i in os.listdir(train_dir):\n",
    "    print(train_dir+\"/\"+i)\n",
    "    print(len(os.listdir(train_dir+\"/\"+i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split random train dataset\n",
    "\n",
    "import random\n",
    "\n",
    "def split_train_balanced(string, nb):\n",
    "    class_train_balanced = []\n",
    "    for i in range(len(string)):\n",
    "        class_train = random.sample(string[i], k=nb)\n",
    "        class_train_balanced.append(class_train)\n",
    "    return class_train_balanced\n",
    "\n",
    "train_balanced = split_train_balanced(string_train, nb=400)\n",
    "#nb=400, for 400 for each categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use copy_file to move file to train folder\n",
    "train_balanced_img = copy_file(source_train,dest_train, train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split random test dataset \n",
    "\n",
    "test_list_choice = []\n",
    "for i in range(len(os.listdir(train_dir))):\n",
    "    test_list = list(set(string_train[i]) - set(train_balanced[i]))\n",
    "    test_list_choice.append(test_list)\n",
    "\n",
    "test_balanced = split_train_balanced(test_list_choice, nb=80)\n",
    "#nb=80 for 20% of 400 img\n",
    "\n",
    "# Use copy_file to move file to train folder\n",
    "test_balanced_img = copy_file(source_test,dest_test,test_balanced)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
